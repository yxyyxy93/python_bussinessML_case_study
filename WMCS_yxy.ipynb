{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    <br style =\"font-family:UCL-SoM-Outline;color:#EA7600\"> GROUP COURSEWORK </br> \n",
    "    </p>\n",
    "</h1>\n",
    "\n",
    "<div class=\"image\">\n",
    "\n",
    "<img src=\"./figures/som_ft.png\" width=\"70%\"  align=\"right\">\n",
    "<h4>\n",
    "          <p style=\"font-size:18pt\">MSIN0097 Predictive Analytics</p>\n",
    "          <p style=\"font-size:18pt;font-family:UCL-SoM-Solid; color:#EA7600;\">Student Name: <u>**EDIT**</u> </p> \n",
    "          <p style=\"font-size:18pt;font-family:UCL-SoM-Solid; color:#EA7600;\">ID: <u>**EDIT**</u> </p> \n",
    "          <p style=\"font-size:18pt;font-family:UCL-SoM-Solid; color:#EA7600;\">Email: <u>**EDIT**</u> </p> \n",
    "\n",
    "</h4>\n",
    "\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSEWORK: WARNER MUSIC\n",
    "\n",
    "\n",
    "\n",
    "### PREDICTING THE SUCCESS OF ARTISTS ON SPOTIFY\n",
    "\n",
    "Please complete the sections of this Notebook with supporting code and markup analysis where appropriate. During this coursework you will:\n",
    "\n",
    "- Understand the specific business forecast task \n",
    "- Prepare a dataset, clean and impute where necessary \n",
    "- Train an ensemble classifier \n",
    "- Evaluate the performance and comment of success and failure modes\n",
    "- Complete all necessary stages of the data science process \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be around 100 words per ACTION cell, but use the wordcount over the duration of the Notebook at your discretion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Please use the below green cell, when writing your comments in markup.**\n",
    "* **Please feel free to add extra code cells in the notebook if needed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b> Title </b> (Optional)\n",
    "\n",
    "<p>Content</p> \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Business Case Understanding\n",
    "\n",
    "### INTRODUCTION\n",
    "\n",
    "Over the last few years, the music industry has been dominated by digital streaming services, which produce vast amounts of data on listeners and their preferences. \n",
    "\n",
    "This has required major players in the industry to adopt a data driven approach to content delivery in order to stay competitive. \n",
    "\n",
    "Warner Music Group is looking to leverage its rich database to better understand the factors that have the most significant impact on the success of a new artist. This will allow them to optimize the allocation of resources when signing and promoting new artists.\n",
    "\n",
    "Warner’s (large) database contains several sources of data, including the streaming platforms Spotify, Amazon Live and Apple Music. \n",
    "\n",
    "For this case study, we will be looking using the Spotify dataset to predict the success of artists. In particular, we want to understand the role of Spotify playlists on the performance of artist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Music\n",
    "\n",
    "When artists release music digitally, details of how their music is streamed can be closely monitored. \n",
    "\n",
    "Some of these details include:\n",
    "\n",
    "- How listeners found their music (a recommendation, a playlist)\n",
    "- Where and when (a routine visit to the gym, a party, while working). \n",
    "- On what device (mobile / PC)\n",
    "- And so on…\n",
    "\n",
    "Spotify alone *process nearly 1 billion streams every day* (Dredge, 2015) and this streaming data is documented in detail every time a user accesses the platform. \n",
    "\n",
    "Analyzing this data potentially enables us to gain a much deeper insight into customers’ listening behavior and individual tastes. \n",
    "\n",
    "Spotify uses it to drive their recommender systems – these tailor and individualize content as well as helping the artists reach wider and more relevant audiences. \n",
    "\n",
    "Warner Music would like to use it to better understand the factors that influence the *future success of its artists*, *identify potentially successful acts* early on in their careers and use this analysis to make resource decisions about how they market and support their artists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are Spotify Playlists and why are relevant today?\n",
    "\n",
    "A playlist is a group of tracks that you can save under a name, listen to, and update at your leisure. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'figures/spotify_playlist_image.png' width=\"50%\"  align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 1. Screen shot of Spotify product show artists and playlists.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spotify currently has more than two billion publicly available playlists, many of which are curated by Spotify’s in-house team of editors. \n",
    "\n",
    "The editors scour the web on a daily basis to remain up-to-date with the newest releases, and to create playlists geared towards different desires and needs. \n",
    "\n",
    "Additionally, there are playlists such as [Discover Weekly](https://www.spotify.com/uk/discoverweekly/) and [Release Radar](https://support.spotify.com/uk/using_spotify/playlists/release-radar/) that use self-learning algorithms to study a user’s listening behavior over time and recommend songs tailored to his/her tastes.\n",
    "\t\n",
    "The figure below illustrates the progression of artists on Spotify Playlists:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'figures/playlist_heirarchy.png' width=\"80%\"  align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2. Figure to illustarte selecting artists and building audience profiles over progressively larger audiences of different playlists. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The artist pool starts off very dense at the bottom, as new artists are picked up on the smaller playlists, and thins on the way to the top, as only the most promising of them make it through to more selective playlists. The playlists on the very top contain the most successful, chart-topping artists.\n",
    "\n",
    "An important discovery that has been made is that certain playlists have more of an influence on the popularity, stream count and future success of an artist than others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'figures/playlist_lift.png' width=\"80%\"  align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Figure 3. Figure to illustrate taking song stream data and using it to predict the trajectory, and likely success, of Warner artists. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, some playlists have been seen to be pivotal in the careers of successful artists. Artists that do make it onto one of these *key* playlists frequently go on to become highly ranked in the music charts. \n",
    "\n",
    "It is the objective of Warner’s [A&R](https://en.wikipedia.org/wiki/Artists_and_repertoire) team to identify and sign artists before they achieve this level of success i.e. before they get selected for these playlists, in order to increase their ROI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUSINESS PROBLEM → DATA PROBLEM\n",
    "\n",
    "Now that we have a better understanding of the business problem, we can begin to think about how we could model this problem using data. \n",
    "\n",
    "The first thing we can do is defining a criterion for measuring artist success. \n",
    "\n",
    "Based on our business problem, one way in which we can do this is to create a binary variable representing the success / failure of an artist and determined by whether a song ends up on a key playlist (1), or not (0). We can then generate features for that artist to determine the impact they have on the success of an artist.\n",
    "\n",
    "Our problem thus becomes a classification task, which can be modeled as follows:\n",
    "\n",
    "### *Artist Feature 1 + Artist Feature 2 …. + Artist Feature N = Probability of Success*\n",
    "\n",
    "where,\n",
    "\n",
    "**Success (1) = Artist Features on Key Playlist**\n",
    "\n",
    "The key playlists we will use for this case study are the 4 listed below, as recommended by Warner Analysts:\n",
    "\n",
    "1.\tHot Hits UK\n",
    "2.\tMassive Dance Hits\n",
    "3.\tThe Indie List\n",
    "4.\tNew Music Friday\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coursework task is to take a look at the Spotify dataset to see how we might be able to set up this classification model.\n",
    "\n",
    "Complete the code sections below to work through the project from start to finish. \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION: Guidance </b> \n",
    "\n",
    "<p>If you need to do something, instructions will appear in a box like this</p> \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <span style=\"color:orange\"> WEEK 2</span>\n",
    "# <span style=\"color:orange\"> Submission Deadline: 30.01.2020</span>\n",
    "## 1. Prepare the problem \n",
    "\n",
    "Run your code on Faculty. We have prepared some of the data for you already. \n",
    "\n",
    "In addition, we have imported a custom module (spotfunc.py) containing useful functions written for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preamble \n",
    "\n",
    "# import sherlockml.filesystem as sfs\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import collections\n",
    "import networkx as nx\n",
    "import seaborn\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "%matplotlib inline\n",
    "\n",
    "# Import custom functions from library, named 'spotfunc'\n",
    "import spotfunc as spotfunc_v2\n",
    "\n",
    "# sfs.get('/input/spotfunc.py', 'spotfunc.py')\n",
    "# sfs.get('/input/playlists_ids_and_titles.csv', 'playlists_ids_and_titles.csv')\n",
    "# sfs.get('/input/new artists2015onwards.csv', 'newartists2015onwards.csv')\n",
    "\n",
    "# Add more stuff here as necessary \n",
    "\n",
    "\n",
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Import custom functions from library, named 'spotfunc'\n",
    "import spotfunc as spotfunc_v2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2. Data Understanding\n",
    "\n",
    "<br>\n",
    "A year’s worth of Spotify streaming data in the WMG database amounts to approximately 50 billion rows of data i.e. 50 billion streams (1.5 to 2 terabytes worth), with a total of seven years of data stored altogether (2010 till today).\n",
    "\n",
    "For the purposes of this case study, we will be using a sample of this data. The dataset uploaded on the Faculty server is about 16GB, containing data from 2015 - 2017. Given the limits on RAM and cores, we will be taking a further sample of this data for purposes of this case study: a 10% random sample of the total dataset, saved as 'cleaned_data.csv'. \n",
    "\n",
    "*Note: The code for this sampling in included below, but commented out.*\n",
    "\n",
    "We can begin with reading in the datasets we will need. We will be using 2 files: \n",
    "1. Primary Spotify dataset\n",
    "2. Playlist Name Mapper (only playlist IDs provided in primary dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (2,13) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 3805499\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read in sampled data\n",
    "data = pd.read_csv('cleaned_data.csv')\n",
    "print('rows:',len(data))\n",
    "\n",
    "# Keep a copy of original data in case of changes made to dataframe\n",
    "all_artists = data.copy()\n",
    "\n",
    "# select the useful columns\n",
    "focuses = ['log_time', 'artist_name', 'track_name', 'isrc', 'customer_id', \n",
    "         'birth_year', 'postal_code', 'country_code', \n",
    "         'gender', 'stream_source_uri', \n",
    "           'hour', 'playlist_id', 'playlist_name', \n",
    "           'stream_length', 'year', 'region_code']\n",
    "\n",
    "# decrease the rows for process speed\n",
    "all_artists = all_artists[focuses][0:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3805499 entries, 0 to 3805498\n",
      "Data columns (total 45 columns):\n",
      "Unnamed: 0           int64\n",
      "Unnamed: 0.1         int64\n",
      "Unnamed: 0.1.1       object\n",
      "day                  int64\n",
      "log_time             object\n",
      "mobile               bool\n",
      "track_id             object\n",
      "isrc                 object\n",
      "upc                  float64\n",
      "artist_name          object\n",
      "track_name           object\n",
      "album_name           object\n",
      "customer_id          object\n",
      "postal_code          object\n",
      "access               object\n",
      "country_code         object\n",
      "gender               object\n",
      "birth_year           float64\n",
      "filename             object\n",
      "region_code          object\n",
      "referral_code        float64\n",
      "partner_name         object\n",
      "financial_product    object\n",
      "user_product_type    object\n",
      "offline_timestamp    float64\n",
      "stream_length        float64\n",
      "stream_cached        float64\n",
      "stream_source        object\n",
      "stream_source_uri    object\n",
      "stream_device        object\n",
      "stream_os            object\n",
      "track_uri            object\n",
      "track_artists        object\n",
      "source               float64\n",
      "DateTime             object\n",
      "hour                 int64\n",
      "minute               int64\n",
      "week                 int64\n",
      "month                int64\n",
      "year                 int64\n",
      "date                 object\n",
      "weekday              int64\n",
      "weekday_name         object\n",
      "playlist_id          object\n",
      "playlist_name        object\n",
      "dtypes: bool(1), float64(7), int64(9), object(28)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by taking a look at what the Spotify data looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the data is a unique stream – every time a user streams a song in the Warner Music catalogue for at least 30 seconds it becomes a row in the database. Each stream counts as a ‘transaction’, the value of which is £0.0012, and accordingly, 1000 streams of a song count as a ‘sale’ (worth £1) for the artist. The dataset is comprised of listeners in Great Britain only.\n",
    "\n",
    "Not all the columns provided are relevant to us. Lets take a look at some basic properties of the dataset, and identify the columns that are important for this study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns we will be using for this case study are:\n",
    "\n",
    "* Log Time – timestamp of each stream\n",
    "* Artist Name(s) – some songs feature more than one artist\n",
    "* Track Name\n",
    "* ISRC - (Unique code identifier for that version of the song, i.e. radio edit, album version, remix etc.)\n",
    "* Customer ID\n",
    "* Birth Year\n",
    "* Location of Customer\n",
    "* Gender of Customer\n",
    "* Stream Source URI – where on Spotify was the song played – unique playlist ID, an artist’s page, an album etc.\n",
    "\n",
    "Now, we can take a closer look at trends in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION: Inspect the data </b> \n",
    "\n",
    "Make sure you understand the data. Use methods like **data.head()**, **data.info()**, etc.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the data is a unique stream – every time a user streams a song in the Warner Music catalogue for at least 30 seconds it becomes a row in the database. Each stream counts as a ‘transaction’, the value of which is £0.0012, and accordingly, 1000 streams of a song count as a ‘sale’ (worth £1) for the artist. The dataset is comprised of listeners in Great Britain only.\n",
    "\n",
    "Not all the columns provided are relevant to us. Lets take a look at some basic properties of the dataset, and identify the columns that are important for this study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns you should *focus* on for this case study are:\n",
    "\n",
    "* Log Time – timestamp of each stream\n",
    "* Artist Name(s) – some songs feature more than one artist\n",
    "* Track Name\n",
    "* ISRC - (Unique code identifier for that version of the song, i.e. radio edit, album version, remix etc.)\n",
    "* Customer ID\n",
    "* Birth Year\n",
    "* Location of Customer\n",
    "* Gender of Customer\n",
    "* Stream Source URI – where on Spotify was the song played – unique playlist ID, an artist’s page, an album etc.\n",
    "* Playlist ID/Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLORATORY ANALYSIS AND PLOTS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at the data set in more detail. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION: Exploratory analysis </b> \n",
    "\n",
    "<p>As demonstrated in class, explore various distribution of the data. Comment on any patterns you can see.</p>\n",
    "\n",
    "<p>- Highlight on any potential uncertainties or peculiarities that you observe. </p> \n",
    "\n",
    "<p>- Variables you might explore, include, but are not limited to: Age, Gender, Stream counts and playlists.</p>\n",
    "\n",
    "<p> - Use figures, plots and visualization as necessary.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load laylist data\n",
    "playlist_ids_and_titles = pd.read_csv('playlists_ids_and_titles.csv',encoding = 'latin-1',error_bad_lines=False, warn_bad_lines=False)\n",
    "'''\n",
    "error_bad_lines : bool, default True\n",
    "    Lines with too many fields (e.g. a csv line with too many commas) will by\n",
    "    default cause an exception to be raised, and no DataFrame will be returned.\n",
    "    If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
    "    returned.\n",
    "warn_bad_lines : bool, default True\n",
    "    If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
    "    \"bad line\" will be output.\n",
    "'''\n",
    "# Keep only those with 22 characters (data cleaning)\n",
    "playlist_mapper = playlist_ids_and_titles[playlist_ids_and_titles.id.str.len()==22].drop_duplicates(['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44914"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_ids_and_titles.id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15965"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_ids_and_titles.name.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "????                      237\n",
      "?????                     170\n",
      "?                         133\n",
      "???                       110\n",
      "??                        102\n",
      "                         ... \n",
      "Guns N' Roses Best Of       1\n",
      "Amo....                     1\n",
      "Satin Jackets Komplete      1\n",
      "Lil' Kleine ? Loterij       1\n",
      "Barnlåtar                   1\n",
      "Name: name, Length: 178594, dtype: int64\n",
      "\n",
      "\n",
      "4vPhNgntxszCgsTr3VnSty    134\n",
      "5lArI7KwgEiNee02PLwbxf    103\n",
      "5AzwPcNtXLcK1oJmwiAPSv     97\n",
      "6miH7roh7HasAUoz7edprz     96\n",
      "0gbp4yKmnkkb5FcVDUszog     93\n",
      "                         ... \n",
      "3DggvvsuE5UzuLcROfKpvM      1\n",
      "697Jj880f658IsHbaHE0rG      1\n",
      "6xpGQEXBUSA9XZn5xVvFKD      1\n",
      "7KKMVGc5oGWNeutcl9F8hU      1\n",
      "6PS7VGfCoamJevWUTU70iH      1\n",
      "Name: id, Length: 149645, dtype: int64\n",
      "\n",
      "\n",
      "1a8of2cZVCve2Dw1JedUO0    1\n",
      "37i9dQZF1DWYBUdckfg1va    1\n",
      "0CyjzeuScmvphm8aCoT0W7    1\n",
      "0upd8IDqS3iRDONIIhOjPq    1\n",
      "5R1PY0A0KbBmRgLp0eYSCk    1\n",
      "                         ..\n",
      "59ibpVKYJqIft6Tywuxxhz    1\n",
      "1nKaXYyeWAxhwPiYAGDuHa    1\n",
      "232hhbz9RX8bDh5LlFeCLN    1\n",
      "3YMASrCc08y06Z5DUz16gv    1\n",
      "6PS7VGfCoamJevWUTU70iH    1\n",
      "Name: id, Length: 149589, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(playlist_ids_and_titles.name.value_counts())\n",
    "print('\\n')\n",
    "print(playlist_ids_and_titles.id.value_counts())\n",
    "print('\\n')\n",
    "print(playlist_mapper.id.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <span style=\"color:orange\"> WEEK 3 Assignment</span>\n",
    "# <span style=\"color:orange\"> Submission Deadline: 13.02.2020</span>\n",
    "\n",
    "## 3.\tData Preperation and Feature Engineering\n",
    "<br>\n",
    "From our business understanding, we know that our criteria for success is whether or not an artist has been on one of 4 key playlists.  The column ‘stream_source_uri’, contains data about the source of the stream – whether it was from an artist’s page, an album, a playlist etc. \n",
    "\n",
    "For streams coming from different playlists, only the Spotify URI code is provided. To make sense of this column and identify our key playlists, we can use the additional table provided that we cleaned above and named 'playlist_mapper'.\n",
    "\n",
    "We can being by out data preperation by subsetting the 4 key playlists we are interested in and creating our dependent variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Dependent Variable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION: Dependant variable </b> \n",
    "\n",
    "<p> Set up the problem as one of classification, selecting the relevant playlists as the variable we are trying to model.</p>\n",
    "\n",
    "<p> Write useful helper functions to support creating of the feature vector and target vector </p>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_multi_name(df, keyword=\",\", column=\"verbatimEventDate\"):\n",
    "    \"\"\"split on keyword in column for an enumeration and create extra record\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        DataFrame with a double field entry in one or more values\n",
    "    keyword: str\n",
    "        word/character to split the double records on\n",
    "    column: str\n",
    "        column name to use for the decoupling of the records\n",
    "    \"\"\"\n",
    "    df[column] = df[column].str.split(keyword)\n",
    "    df = df.explode(column)\n",
    "    \n",
    "    df[column] = df[column].str.strip()  # remove white space around the words\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637\n",
      "(50000,)\n",
      "(50637,)\n"
     ]
    }
   ],
   "source": [
    "# split in row (the artists)  \n",
    "all_artists_split = solve_multi_name(all_artists.copy(),\n",
    "                  \"&\", \n",
    "                  column=\"artist_name\")\n",
    "\n",
    "print(all_artists.artist_name.str.contains('&').sum())\n",
    "print(all_artists.artist_name.shape)\n",
    "print(all_artists_split.artist_name.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_successful_artists(data, Playlists_id): \n",
    "    # change the index to artist\n",
    "    # data.set_index('artist_name', append=False, inplace=True, drop=False)\n",
    "    \n",
    "    # select relevant playlists \n",
    "    relevant_playlists = data['playlist_id'].isin(Playlists_id)\n",
    "    \n",
    "    # Playlists = '|'.join(Playlists)\n",
    "    # relevant_playlists = data['playlist_name'].str.contains(Playlists)\n",
    "    # relevant_playlists = data['playlist_name'].isin(Playlists) # ignored the multi playlists!\n",
    "\n",
    "    # Define Dependent Variable\n",
    "    data['success'] = relevant_playlists\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>17513</td>\n",
       "      <td>3DL9G1ApvJDIR4IhWIJ8AQ</td>\n",
       "      <td>New Music Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25618</td>\n",
       "      <td>6FfOZSAN3N6u7v81uS7mxZ</td>\n",
       "      <td>Hot Hits UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27234</td>\n",
       "      <td>2mnRUIMJWqooAWlMjrlghi</td>\n",
       "      <td>New Music Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32459</td>\n",
       "      <td>1EnTBEgCWiTX2YHyAzkcFn</td>\n",
       "      <td>New Music Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35117</td>\n",
       "      <td>37i9dQZF1DWXJfnUiYjUKT</td>\n",
       "      <td>New Music Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72659</td>\n",
       "      <td>0dLTdpGyfO0PSyYXInvRd5</td>\n",
       "      <td>New Music Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83239</td>\n",
       "      <td>6wx0wiD9V6JJ2EOh4KM3Ox</td>\n",
       "      <td>New Music Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91903</td>\n",
       "      <td>35PofY2z4SqqbynOKXmdYV</td>\n",
       "      <td>New Music Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94405</td>\n",
       "      <td>37i9dQZF1DX5uokaTN4FTR</td>\n",
       "      <td>Massive Dance Hits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110448</td>\n",
       "      <td>47CSE0kHnUAZosPD3ErRwV</td>\n",
       "      <td>NEW MUSIC FRIDAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131216</td>\n",
       "      <td>37i9dQZF1DWVTKDs2aOkxu</td>\n",
       "      <td>The Indie List</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133600</td>\n",
       "      <td>4vGgUbD6tW2xMTABaVzCXo</td>\n",
       "      <td>New Music Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137620</td>\n",
       "      <td>7lc3WCkMnfPyFbgTdVgSSh</td>\n",
       "      <td>hot hits uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140255</td>\n",
       "      <td>37i9dQZF1DX4JAvHpjipBk</td>\n",
       "      <td>New Music Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151213</td>\n",
       "      <td>37i9dQZF1DWY4lFlS4Pnso</td>\n",
       "      <td>Hot Hits UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170678</td>\n",
       "      <td>37i9dQZF1DWT2SPAYawYcO</td>\n",
       "      <td>New Music Friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id                name\n",
       "17513   3DL9G1ApvJDIR4IhWIJ8AQ    New Music Friday\n",
       "25618   6FfOZSAN3N6u7v81uS7mxZ         Hot Hits UK\n",
       "27234   2mnRUIMJWqooAWlMjrlghi    New Music Friday\n",
       "32459   1EnTBEgCWiTX2YHyAzkcFn    New Music Friday\n",
       "35117   37i9dQZF1DWXJfnUiYjUKT    New Music Friday\n",
       "72659   0dLTdpGyfO0PSyYXInvRd5    New Music Friday\n",
       "83239   6wx0wiD9V6JJ2EOh4KM3Ox    New Music Friday\n",
       "91903   35PofY2z4SqqbynOKXmdYV    New Music Friday\n",
       "94405   37i9dQZF1DX5uokaTN4FTR  Massive Dance Hits\n",
       "110448  47CSE0kHnUAZosPD3ErRwV    NEW MUSIC FRIDAY\n",
       "131216  37i9dQZF1DWVTKDs2aOkxu      The Indie List\n",
       "133600  4vGgUbD6tW2xMTABaVzCXo    New Music Friday\n",
       "137620  7lc3WCkMnfPyFbgTdVgSSh         hot hits uk\n",
       "140255  37i9dQZF1DX4JAvHpjipBk    New Music Friday\n",
       "151213  37i9dQZF1DWY4lFlS4Pnso         Hot Hits UK\n",
       "170678  37i9dQZF1DWT2SPAYawYcO    New Music Friday"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 key Playlists\n",
    "key_playlists=[\"Hot Hits UK\",\"Massive Dance Hits\",\"The Indie List\",\"New Music Friday\"]\n",
    "\n",
    "# select relevant playlists id\n",
    "Playlists_id_mask = playlist_mapper[\"name\"].str.lower().isin(x.lower() for x in key_playlists) # case insensitive \n",
    "Playlists_id = playlist_mapper[Playlists_id_mask]\n",
    "Playlists_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the list of the id \n",
    "df_new = get_successful_artists(all_artists_split.copy(), Playlists_id.id.tolist())\n",
    "success_artist = df_new.loc[df_new['success']==True]['artist_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50637, 17)\n",
      "Index(['log_time', 'artist_name', 'track_name', 'isrc', 'customer_id',\n",
      "       'birth_year', 'postal_code', 'country_code', 'gender',\n",
      "       'stream_source_uri', 'hour', 'playlist_id', 'playlist_name',\n",
      "       'stream_length', 'year', 'region_code', 'success'],\n",
      "      dtype='object')\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(df_new.shape)\n",
    "print(df_new.columns)\n",
    "print(df_new.success.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vinyl on HBO             6014\n",
       "Xavier Dunn              3903\n",
       "RedOne                   3656\n",
       "Dae Dae                  2409\n",
       "TroyBoi                  1849\n",
       "                         ... \n",
       "Jazztronik                  1\n",
       "The Stills-Young Band       1\n",
       "Giuseppe Gibboni            1\n",
       "The Dukes                   1\n",
       "Josh Kempen                 1\n",
       "Name: artist_name, Length: 249, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.artist_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created our dependent variable – whether an artist is successful or not, we can look at generating a set of features, based on the columns within our dataset, that we think might best explain the reasons for this success. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FEATURE ENGINEERING**\n",
    "\n",
    "There are a large number of factors that could have an impact on the success of an artist, such as the influence of a playlist, or the popularity of an artist in a certain geographical region. \n",
    "\n",
    "To build a predictive model for this problem, we first need to turn these (largely qualitative) factors into measurable quantities. Characteristics like ‘influence’ and ‘popularity’ need to be quantified and standardized for all artists, to allow for a fair comparison. \n",
    "\n",
    "The accurateness of these numerical estimates will be the fundamental driver of success for any model we build. \n",
    "There are many approaches one might take to generate features. Based on the data columns available to us, a sensible approach is to divide our feature set into three groups:\n",
    "\n",
    "1.\tArtist Features\n",
    "2.\tPlaylist Features\n",
    "3.\tUser-base features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist features\n",
    "\n",
    "*\tStream count\n",
    "*\tTotal Number of users\n",
    "*\tPassion Score \n",
    "\n",
    "The metric passion score is a metric suggested to us by Warner business analysts. \n",
    "\n",
    "It is defined as the number of stream divided by the total number of users. \n",
    "\n",
    "Warner analysts believe that repeated listens by a user is a far more indicative future success that simply total number of listens or total unique users. By including this in your model, we can evaluate whether this metric in fact might be of any significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION: Artist features </b> \n",
    "\n",
    "<p> Write useful functions to create these new features. </p>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stream count per artist\n",
    "stream_count = df_new.groupby(['artist_name'])['artist_name'].count()\n",
    "# df_artist = pd.DataFrame(data=stream_count, columns=[\"artist_name\", \"Stream count\"])\n",
    "\n",
    "# convert the series to dataframe indexed by artist name\n",
    "stream_count = stream_count.to_frame()\n",
    "df_artist = stream_count.rename(columns={'artist_name':'stream_count'})\n",
    "df_artist.reset_index(inplace=True)\n",
    "\n",
    "# df_artist = stream_count.rename(columns={'index':'artist_name', 'artist_name':'stream_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of users per artist\n",
    "# all_artists.groupby(['artist_name'])['customer_id'].count().reset_index(name='count').sort_values(['count'], ascending=False) \\\n",
    "Number_users = df_new.groupby(['artist_name'])['customer_id'].nunique().to_list() \n",
    "# Return number of unique elements in the object.\n",
    "\n",
    "df_artist['num_users'] = Number_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passion Score\n",
    "df_artist['passion_score'] = df_artist['stream_count'] / df_artist['num_users']\n",
    "\n",
    "# merge playlist\n",
    "# df_artist_list = pd.merge(df_artist, all_artists[['artist_name', 'playlist_name']], on='artist_name', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playlist Features\n",
    "\n",
    "Understanding an artist’s growth as a function of his/her movement across different playlists is potentially key to understanding how to identify and breakout new artists on Spotify. \n",
    "\n",
    "In turn, this could help us identify the most influential playlists and the reasons for their influence.\n",
    "\n",
    "One way to model the effect of playlists on an artist’s performance has been to include them as categorical features in our model, to note if there are any particular playlists or combinations of playlists that are responsible for propelling an artist to future success:\n",
    "\n",
    "### *Artist Feature 1 + Artist Feature 2 …. + Artist Feature N = Probability of Success*\n",
    "**\n",
    "Success (1) = Artist Features on Key Playlist\n",
    "Failure (0) = Artist Not Featured on Key Playlist\n",
    "**\n",
    "\n",
    "Where,\n",
    "\n",
    "**\n",
    "⇒Artist Feature N = Prior Playlist 1 + Prior Playlist 2 +…Prior Playlist N\n",
    "**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION: Playlist features </b> \n",
    "\n",
    "<p> Write useful functions to create new playlist features, like those listed in the cell above. </p>\n",
    "\n",
    "<p> Are there other sensible ones you could suggest, work in your group to think about what other features might be useful and whether you can calculate them with the data you have </p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1207,)\n",
      "(1207,)\n",
      "1.000000    1082\n",
      "2.000000       8\n",
      "1.111111       4\n",
      "1.250000       4\n",
      "1.125000       3\n",
      "            ... \n",
      "1.083333       1\n",
      "1.039415       1\n",
      "1.029412       1\n",
      "1.033898       1\n",
      "1.015625       1\n",
      "Name: passion_score, Length: 93, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# using .groupby to 2 items simultantanously\n",
    "pasc = df_new.groupby(['artist_name', 'playlist_name'])['playlist_name'].count()\n",
    "panou = df_new.groupby(['artist_name', 'playlist_name'])['customer_id'].nunique()\n",
    "print(pasc.shape)\n",
    "print(panou.shape)\n",
    "\n",
    "df_playlist = pasc.to_frame().rename(columns={'playlist_name':'stream_counts'})\n",
    "df_playlist['number_of_users'] = panou.to_list()\n",
    "df_playlist['passion_score'] = df_playlist['stream_counts'] / df_playlist['number_of_users']\n",
    "print(df_playlist.passion_score.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you could divide up the work in the group by getting different people to calculate different features \n",
    "\n",
    "def playlist_avg_stream_counts(data):\n",
    "    pasc = data.groupby('playlist_name')['playlist_name'].count()\n",
    "    return pasc\n",
    "\n",
    "def playlist_avg_number_of_users(data):\n",
    "    panou = df_new.groupby('playlist_name')['customer_id'].nunique()\n",
    "    return panou\n",
    "\n",
    "def playlist_avg_passion_score(data):\n",
    "    data['passion_score'] = data['stream_count'] / data['num_users']\n",
    "    \n",
    "    return data\n",
    "\n",
    "# make sure you think they are actually being calculated correctly\n",
    "# how could you demonstrate the code you write is working correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(797,)\n",
      "(797,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>stream_count</th>\n",
       "      <th>num_users</th>\n",
       "      <th>passion_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SEPTEMBER 2016 TOP HITS</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fall 2015 Hip Hop / R&amp;B playlist</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hollister Vibe 2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>#AlDub: Happily Ever After</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>#BESTE INDIE</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>792</td>\n",
       "      <td>stormzy-standard</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>793</td>\n",
       "      <td>tbh eat my pu$$y</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>794</td>\n",
       "      <td>Éxitos MX</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>795</td>\n",
       "      <td>Éxitos Party 2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>796</td>\n",
       "      <td>Ö3-Hörerplaylist</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>797 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         playlist_name  stream_count  num_users  passion_score\n",
       "0              SEPTEMBER 2016 TOP HITS             5          3       1.666667\n",
       "1     Fall 2015 Hip Hop / R&B playlist             1          1       1.000000\n",
       "2                  Hollister Vibe 2016             1          1       1.000000\n",
       "3           #AlDub: Happily Ever After             2          2       1.000000\n",
       "4                         #BESTE INDIE             2          1       2.000000\n",
       "..                                 ...           ...        ...            ...\n",
       "792                   stormzy-standard             1          1       1.000000\n",
       "793                   tbh eat my pu$$y             1          1       1.000000\n",
       "794                          Éxitos MX             1          1       1.000000\n",
       "795                  Éxitos Party 2016             1          1       1.000000\n",
       "796                   Ö3-Hörerplaylist             1          1       1.000000\n",
       "\n",
       "[797 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pasc = playlist_avg_stream_counts(df_new)\n",
    "panou = playlist_avg_number_of_users(df_new)\n",
    "print(pasc.shape)\n",
    "print(panou.shape)\n",
    "\n",
    "# convert the series to dataframe indexed by artist name\n",
    "df_playlist = pasc.to_frame().rename(columns={'playlist_name':'stream_count'})\n",
    "df_playlist.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "df_playlist['num_users'] = panou.to_list()\n",
    "# passion score\n",
    "df_playlist = playlist_avg_passion_score(df_playlist)\n",
    "df_playlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-base features\n",
    "\n",
    "We can use the age and gender columns to create an audience profile per artist.\n",
    "*\tGender Percentage Breakdown\n",
    "*\tAge vector quantization \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION: User features </b> \n",
    "\n",
    "<p> Write useful functions to create new user features, like those listed in the cell above. </p>\n",
    "\n",
    "<p> Are there other sensible ones you could suggest? Work in your group to think about what other features might be useful and whether you can calculate them with the data you have. Justify your reasoning. </p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_name\n",
       "3JS             0.500000\n",
       "AGWA            1.000000\n",
       "AV AV AV        0.000000\n",
       "AVVAH           0.166667\n",
       "Adan Carmona    0.000000\n",
       "                  ...   \n",
       "Yellow Claw     0.795455\n",
       "Young Spray     0.820128\n",
       "Zac Brown       0.543478\n",
       "Zak             0.000000\n",
       "livetune+       0.000000\n",
       "Length: 249, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gender breakdown\n",
    "df_gender = df_new.copy()\n",
    "\n",
    "def gender_percentage(df_gen, gender='male'):\n",
    "    if (len(df_gen)!=0):\n",
    "        df_gen = df_gen.dropna(subset=['gender'])  # clean the data\n",
    "        df_gen = df_gen.drop_duplicates(subset=['customer_id']) \n",
    " \n",
    "        perc = df_gen[df_gen.gender==gender].shape[0]/df_gen.shape[0]\n",
    "        return perc\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "gender_per = df_gender.groupby('artist_name').apply(gender_percentage, gender='male')\n",
    "gender_per\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>stream_count</th>\n",
       "      <th>num_users</th>\n",
       "      <th>passion_score</th>\n",
       "      <th>male_per</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3JS</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AGWA</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AV AV AV</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AVVAH</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Adan Carmona</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>Yellow Claw</td>\n",
       "      <td>94</td>\n",
       "      <td>89</td>\n",
       "      <td>1.056180</td>\n",
       "      <td>0.795455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>Young Spray</td>\n",
       "      <td>498</td>\n",
       "      <td>476</td>\n",
       "      <td>1.046218</td>\n",
       "      <td>0.820128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>Zac Brown</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.543478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>Zak</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>livetune+</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist_name  stream_count  num_users  passion_score  male_per\n",
       "0             3JS             3          2       1.500000  0.500000\n",
       "1            AGWA             2          2       1.000000  1.000000\n",
       "2        AV AV AV             1          1       1.000000  0.000000\n",
       "3           AVVAH             6          6       1.000000  0.166667\n",
       "4    Adan Carmona             1          1       1.000000  0.000000\n",
       "..            ...           ...        ...            ...       ...\n",
       "244   Yellow Claw            94         89       1.056180  0.795455\n",
       "245   Young Spray           498        476       1.046218  0.820128\n",
       "246     Zac Brown            47         47       1.000000  0.543478\n",
       "247           Zak             1          1       1.000000  0.000000\n",
       "248     livetune+             1          1       1.000000  0.000000\n",
       "\n",
       "[249 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artist['male_per'] = gender_per.to_list()\n",
    "df_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>stream_count</th>\n",
       "      <th>num_users</th>\n",
       "      <th>passion_score</th>\n",
       "      <th>male_per</th>\n",
       "      <th>ave_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3JS</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AGWA</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AV AV AV</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AVVAH</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Adan Carmona</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>Yellow Claw</td>\n",
       "      <td>94</td>\n",
       "      <td>89</td>\n",
       "      <td>1.056180</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>25.138298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>Young Spray</td>\n",
       "      <td>498</td>\n",
       "      <td>476</td>\n",
       "      <td>1.046218</td>\n",
       "      <td>0.820128</td>\n",
       "      <td>25.074447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>Zac Brown</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>32.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>Zak</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>livetune+</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist_name  stream_count  num_users  passion_score  male_per    ave_age\n",
       "0             3JS             3          2       1.500000  0.500000  44.000000\n",
       "1            AGWA             2          2       1.000000  1.000000  51.500000\n",
       "2        AV AV AV             1          1       1.000000  0.000000  35.000000\n",
       "3           AVVAH             6          6       1.000000  0.166667  27.000000\n",
       "4    Adan Carmona             1          1       1.000000  0.000000  27.000000\n",
       "..            ...           ...        ...            ...       ...        ...\n",
       "244   Yellow Claw            94         89       1.056180  0.795455  25.138298\n",
       "245   Young Spray           498        476       1.046218  0.820128  25.074447\n",
       "246     Zac Brown            47         47       1.000000  0.543478  32.021277\n",
       "247           Zak             1          1       1.000000  0.000000  19.000000\n",
       "248     livetune+             1          1       1.000000  0.000000  30.000000\n",
       "\n",
       "[249 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Age breakdown\n",
    "\n",
    "def age_mean(df):\n",
    "    df = df.dropna(subset = ['birth_year'])\n",
    "#     df = df[(df.birth_year!='male') & (df.birth_year!='female')]\n",
    "    age = df.year - df.birth_year\n",
    "    \n",
    "    df['age'] = age\n",
    "    \n",
    "    artist_age_mean = df.groupby('artist_name')['age'].mean()\n",
    "    \n",
    "    return artist_age_mean\n",
    "\n",
    "artist_age_mean = age_mean(df_new)\n",
    "\n",
    "# add the average age of users to artist\n",
    "df_artist['ave_age'] = artist_age_mean.to_list()\n",
    "\n",
    "df_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>stream_count</th>\n",
       "      <th>num_users</th>\n",
       "      <th>passion_score</th>\n",
       "      <th>male_per</th>\n",
       "      <th>ave_age</th>\n",
       "      <th>success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3JS</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AGWA</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AV AV AV</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AVVAH</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Adan Carmona</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>Yellow Claw</td>\n",
       "      <td>94</td>\n",
       "      <td>89</td>\n",
       "      <td>1.056180</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>25.138298</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>Young Spray</td>\n",
       "      <td>498</td>\n",
       "      <td>476</td>\n",
       "      <td>1.046218</td>\n",
       "      <td>0.820128</td>\n",
       "      <td>25.074447</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>Zac Brown</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>32.021277</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>Zak</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>livetune+</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist_name  stream_count  num_users  passion_score  male_per  \\\n",
       "0             3JS             3          2       1.500000  0.500000   \n",
       "1            AGWA             2          2       1.000000  1.000000   \n",
       "2        AV AV AV             1          1       1.000000  0.000000   \n",
       "3           AVVAH             6          6       1.000000  0.166667   \n",
       "4    Adan Carmona             1          1       1.000000  0.000000   \n",
       "..            ...           ...        ...            ...       ...   \n",
       "244   Yellow Claw            94         89       1.056180  0.795455   \n",
       "245   Young Spray           498        476       1.046218  0.820128   \n",
       "246     Zac Brown            47         47       1.000000  0.543478   \n",
       "247           Zak             1          1       1.000000  0.000000   \n",
       "248     livetune+             1          1       1.000000  0.000000   \n",
       "\n",
       "       ave_age  success  \n",
       "0    44.000000    False  \n",
       "1    51.500000    False  \n",
       "2    35.000000    False  \n",
       "3    27.000000    False  \n",
       "4    27.000000    False  \n",
       "..         ...      ...  \n",
       "244  25.138298    False  \n",
       "245  25.074447    False  \n",
       "246  32.021277    False  \n",
       "247  19.000000    False  \n",
       "248  30.000000    False  \n",
       "\n",
       "[249 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the success label to df_artist\n",
    "df_artist['success'] = df_artist['artist_name'].isin(success_artist)\n",
    "\n",
    "df_artist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Principle Component Analysis**\n",
    "\n",
    "The data also contains a partial region code of the listener. We might want to consider including the regional breakdown of streams per artist as a feature of our model, to know if streams for certain regions are particularly influential on the future performance of an artist. \n",
    "\n",
    "However, we have over 400 unique regions and like playlists, including them all would lead to too many features and a large sparse matrix. One way in which to extract relevant ‘generalized’ features of each region would be to incorporate census and demographic data, from publicly available datasets. \n",
    "\n",
    "This is however beyond the scope of this courswork. Instead, a better way to summarize the impact of regional variation in streams is to use dimensionality reduction techniques. Here we will use Principle Component Analysis (PCA) to capture the regional variation in stream count.\n",
    "\n",
    "PCA captures the majority of variation in the original feature set and represents it as a set of new orthogonal variables. Each ‘component’ of PCA is a linear combination of every feature, i.e. playlist in the dataset. Use **`scikit-learn`**’s PCA module (Pedregosa, et al., 2011) for generating PCA components.\n",
    "\n",
    "For a comprehensive understanding of how sklearn's PCA module works, please refer to the sklearn documentation. We will using 10 components of PCA in our model.\n",
    "\n",
    "*Note: We could also apply a similar method to condense variation in stream across the 19,600 different playlists in our dataset.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION: PCA features </b> \n",
    "\n",
    "<p> Write useful functions to create new user feature based on regions data. </p>\n",
    "\n",
    "<p> Are there other sensible features you could suggest? Work in your group to think about what other features might be useful and whether you can calculate them with the data you have. Justify your reasoning. </p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use Principle Component Analysis (PCA) to capture the regional variation in stream count.\n",
    "artist_region = df_new.groupby(['artist_name','region_code']).agg({'region_code': ['count']})\n",
    "\n",
    "feature_region = artist_region.unstack().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23942607, -0.31440711, -0.22705292, ..., -0.33945209,\n",
       "        -0.29055457, -0.09128709],\n",
       "       [-0.23942607, -0.31440711, -0.22705292, ..., -0.33945209,\n",
       "        -0.29055457, -0.09128709],\n",
       "       [-0.23942607, -0.31440711, -0.22705292, ..., -0.33945209,\n",
       "        -0.29055457, -0.09128709],\n",
       "       ...,\n",
       "       [-0.23942607, -0.08728317, -0.22705292, ..., -0.18704503,\n",
       "        -0.29055457, -0.09128709],\n",
       "       [-0.23942607, -0.31440711, -0.22705292, ..., -0.33945209,\n",
       "        -0.29055457, -0.09128709],\n",
       "       [-0.23942607, -0.31440711, -0.22705292, ..., -0.33945209,\n",
       "        -0.29055457, -0.09128709]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "artist_region_scaled = scaler.fit_transform(feature_region)\n",
    "\n",
    "artist_region_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_region' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-91ec9a21d35d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_region\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# pca_regions_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_region' is not defined"
     ]
    }
   ],
   "source": [
    "# Region Code PCA\n",
    "\n",
    "from sklearn import decomposition\n",
    "\n",
    "pca = decomposition.PCA(n_components=10)\n",
    "\n",
    "pca.fit(feature_region)\n",
    "\n",
    "# pca_regions_output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>WARNING: PCA features </b> \n",
    "    \n",
    "<p>If you struggle to complete this section successfully <b>please email me</b> and we will provide code to compute the new features. This will help with performance of the classifier in the next stage.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the PCA feature table to make sure the dataframe looks as expected. Comment on anything the looks important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    " #pca_regions_output['pca_ouput_df'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION: PCA plot </b> \n",
    "\n",
    "<p> Use a figure to show which components of PCA explain the majority of variation in the data. Accordingly, use only those components in your further analysis.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data transformation**\n",
    "\n",
    "The final step is to decide whether or not to normalize/transform any of the features. \n",
    "\n",
    "We should normalize data if we are more interested in the relative rather than absolute differences between variables. Given that all the numerical features in our dataset (centrality, lift, influence, gender breakdown, age breakdown) were meaningful, i.e. distances did make a difference;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION: Feature transformation </b> \n",
    "\n",
    "<p> Comment on whether transforming particular features (influence, gender breakdown, age breakdown) is useful. Calculate the transformation where necessary.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we can combine all of our features that we generated above, into a dataframe that can be processed by a machine learning algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df = pd.DataFrame(variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION: Feature transformation </b> \n",
    "\n",
    "<p> Comment on whether transforming particular features (influence, gender breakdown, age breakdown) is useful. Calculate the transformation where necessary.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**\n",
    "\n",
    "Before we can run any models on our dataset, we must make sure it is prepared and cleaned to avoid errors in results. This stage is generally refered to as preprocessing.\n",
    "\n",
    "To begin with, we need to deal with missing data in the dataframe - the ML algorithm will not be able to process NaN or missing values. \n",
    "\n",
    "For this study, we will be imputing missing numerical values, and filling any one which we were not able to imput, with 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION: Missing values </b> \n",
    "\n",
    "<p> Use the <b>Imputer</b> class to alter your final Dataframe that contains your feature vector.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "#from sklearn.preprocessing import Imputer\n",
    "\n",
    "#imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "\n",
    "#fill remaining nan with 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to make sure that none of the variables going into the model are collinear, and if so, we need to remove those variables that are highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION: Multi-collinearity </b> \n",
    "\n",
    "<p> Check and deal with multi-collinearity in your feature set.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove one of highly correlated varibles (test removing other as well)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to take a look out the class balance in our dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the natural bias in our data, i.e. there are more cases of failure than of success in the training and test sets; there is a strong bias toward predicting ‘failure’. Based on our complete (unbalanced classes) training sample, if the model only predicted ‘failure’, we would achieve an accuracy of 88.8%. \n",
    "\n",
    "To give us a more even class balance, without losing too much data, we will sample data from the bigger class to achive a class balance closer to 60-40. \n",
    "\n",
    "There is another way to determine the accuracy of our predictions using a confusion matrix and ROC curve, but more on that later. For now, we will go ahead with sampling the bigger class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION: Class balance </b> \n",
    "\n",
    "<p> Calculate and comment on class balance.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class balance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <span style=\"color:orange\"> WEEK 5 Assignment</span>\n",
    "# <span style=\"color:orange\"> Submission Deadline: 20.02.2020</span>\n",
    "## 4.\tEvaluate algorithms \n",
    "\n",
    "**Model Selection**\n",
    "\n",
    "There are number of classification models available to us via the **`scikit-learn`** package, and we can rapidly experiment using each of them to find the optimal model.\n",
    "\n",
    "Below is an outline of the steps we will take to arrive at the best model:\n",
    "\n",
    "*\tSplit data into training and validation (hold-out) set\n",
    "*\tUse cross-validation to fit different models to training set\n",
    "*\tSelect model with the highest cross-validation score as model of choice\n",
    "*\tTune hyper parameters of chosen model.\n",
    "*\tTest the model on hold-out set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION: Spot-check algorithms </b> \n",
    "\n",
    "<p> Try a mixture of algorithm representations (e.g. instances and trees). </p>\n",
    "\n",
    "<p> Try a mixture of learning algorithms (e.g. different algorithms for learning the same type of representation).<p>\n",
    "\n",
    "<p> Try a mixture of modeling types (e.g. linear and nonlinear functions or parametric and nonparametric).</p>\n",
    "\n",
    "<p> Divide this work up among the different members of your team and then compare and comment on the performance of various approaches.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# YOU CAN EXPERIMENT WITH CLASSIFIERS NOT EXPLICITLY COVERED IN CLASS \n",
    "\n",
    "# classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clf in classifiers:\n",
    "    #clf.fit(X, y)\n",
    "    # score = clf.score(X_test, y_test)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Present Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "To get a better idea of the quality of our predictions, we can plot a confusion matrix and ROC curve. \n",
    "\n",
    "\n",
    "A confusion matrix is a technique for summarizing the performance of a classification algorithm that allows visualization of the performance of an algorithm. \n",
    "\n",
    "Each row of the matrix represents the instances in a predicted class while each column represents the instances in an actual class (or vice versa). \n",
    "\n",
    "The confusion matrix shows the ways in which your classification model is confused when it makes predictions. It gives you insight not only into the errors being made by your classifier but more importantly the types of errors that are being made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION:  Confusion matrix  </b> \n",
    "\n",
    "<p> Comment on the performance of your final algorithm. Repeat analysis from earlier in the Notebook if necessary. </p>\n",
    "\n",
    "<p> Explain confusion matrix results, calculate accuracy and precision etc. </p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve \n",
    "\n",
    "Receiver Operating Characteristic (ROC) curves show the ability of the model to classify subjects correctly across a range of decision thresholds, i.e. it plots the True Positive Rate vs. False Positive Rate at every probability threshold. \n",
    "\n",
    "The AUC summarizes the results of an ROC – it is the probability that a randomly chosen ‘success’ example has a higher probability of being a success than a randomly chosen ‘failure’ example. A random classification would yield an AUC of 0.5, and a perfectly accurate one would yield 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION:  ROC Curve </b> \n",
    "\n",
    "<p> Comment on the performance of your final algorithm. Repeat analysis from earlier in the Notebook if necessary. </p>\n",
    "\n",
    "<p> Explain any observations about the ROC results. </p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ROC curve\n",
    "\n",
    "# Plot classifier ROC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a validated model, we can potentially analyze the features of the model, to understand which ones have had the most impact on predicting an artist’s success. \n",
    "\n",
    "To do this, we can plot the feature importance as determined by the classifier:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ACTION:  Feature importance</b> \n",
    "\n",
    "<p> Where possible, comment on the feature selection and performance of your final algorithm. Repeat analysis from earlier in the Notebook if necessary. </p>\n",
    "\n",
    "<p> Explain any observations about the sensitivity of your final analysis. </p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "**Please provide summaries of the work completed and the outcomes of the analysis**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips completing the coursework \n",
    "\n",
    "- **Faculty** - You are free to run the code on your local machine, but if training timings and memory become an issue then use Faculty to complete the coursework. Technical support for using Faculty will be provided as necessary. \n",
    "\n",
    "\n",
    "- **JIRA** - Assess the different potential work packages and break the overall objectives into a set of tasks and queue them up in the backlog column of the Kanban board. Create new tasks as and when necessary during the course of your analysis. \n",
    "\n",
    "\n",
    "- **Fast First Pass** - Make a first-pass through the project steps as fast as possible. This will give you confidence that you have all the parts that you need and a baseline from which to improve.\n",
    "\n",
    "\n",
    "- **Attempt Every Step** -  It is easy to skip steps, especially if you are not confident or familiar with the tasks of that step. Try and do something at each step in the process, even if it does not contribute to improved accuracy. You can always build upon it later. Don’t skip steps, just reduce their contribution.\n",
    "\n",
    "\n",
    "- **Ratchet Accuracy** - The goal of the project is to achieve relatively good model performance (which ever metric you use to measure this) and give you confidence about the ML project structure and workflow. Every step contributes towards this goal. Treat changes that you make as experiments that increase accuracy as the golden path in the process and reorganize other steps around them. Performance is a ratchet that can only move in one direction (better, not worse).\n",
    "\n",
    "\n",
    "- **Adapt As Needed** - Do not limit your analysis to the instructions provided in Guidelines cells, feel free to expand your analysis beyond them. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
